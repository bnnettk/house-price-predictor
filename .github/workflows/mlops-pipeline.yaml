name: MLops Pipeline

on:
  workflow_dispatch: 
    inputs:
      run_all:
        description: 'Run all jobs'
        required: false
        default: true
      
      run_data_processing:
        description: 'Run data processing job'
        required: false
        default: false

      run_model_training:
        description: 'Run model traing job'
        required: false
        default: false    

      run_build_and_publish:
        description: 'Run build and publish job'
        required: false
        default: false

  release:
    types: [created]
    branches: [ main]
    tags: [ 'v*.*.*']

jobs:
  data-processing:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: 3.11
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Data Processing
        run: |
          python src/data/run_processing.py \
            --input data/raw/house_data.csv \
            --output data/processed/cleaned_house_data.csv

      - name: Feature Engineering
        run: |
          python src/features/engineer.py \
           --input data/processed/cleaned_house_data.csv \
           --output data/processed/featured_house_data.csv \
           --preprocessor models/trained/preprocessor.pkl

      - name: Upload Processed Data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed/featured_house_data.csv

      - name: Upload preprocessor
        uses: actions/upload-artifact@v4
        with:
          name: preprocessor
          path: models/trained/preprocessor.pkl
      
  model-training:
    runs-on: ubuntu-latest
    needs: data-processing

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: 3.11
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/processed

      - name: Start MLflow Server
        run: |
          docker pull ghcr.io/mlflow/mlflow:latest
          docker run -d -p 5000:5000 --name mlflow-server ghcr.io/mlflow/mlflow:latest \
          mlflow server --host 0.0.0.0 \
          --backend-store-uri sqlite:///mlflow.db \
          --default-artifact-root /tmp/mlruns
      
      - name: Wait for MLflow to Start
        run: |
          for i in {1..10}; do
            curl -f "http://localhost:5000/health" || sleep 5;
          done

      - name: Train the Model
        run: |
          mkdir -p models
          python src/models/train_model.py \
          --config configs/model_config.yaml \
          --data data/processed/featured_house_data.csv \
          --models-dir models \
          --mlflow-tracking-uri http://localhost:5000
      

      - name: Upload trained Model
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: models/

      - name: Stop MLflow Server
        run: |
          docker stop mlflow-server || true
          docker rm mlflow-server || true

  build-and-publish:
    runs-on: ubuntu-latest
    needs: model-training

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Download trained model
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: models/

      - name: Download preprocessor
        uses: actions/download-artifact@v4
        with:
          name: preprocessor
          path: models/trained/

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and test
        run: |
          COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
          docker build -t docker.io/${{ vars.DOCKERHUB_USERNAME}}/fastapi:$COMMIT_HASH -f Dockerfile .
          docker run -d -p 8000:8000 --name fastapi-test docker.io/${{ vars.DOCKERHUB_USERNAME}}/fastapi:$COMMIT_HASH
          for i in {1..10}; do
            curl -f "http://localhost:8000/health" && break || sleep 5;
          done
          docker logs fastapi-test

      - name: Clean up Test Container
        run: |
          docker stop fastapi-test || true
          docker rm fastapi-test || true

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          registry: docker.io
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Push
        run: |
          COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
          docker build -t docker.io/${{ vars.DOCKERHUB_USERNAME}}/fastapi:$COMMIT_HASH -t docker.io/${{ vars.DOCKERHUB_USERNAME}}/fastapi:latest -f Dockerfile .
          docker push docker.io/${{ vars.DOCKERHUB_USERNAME}}/fastapi:$COMMIT_HASH
          docker push docker.io/${{ vars.DOCKERHUB_USERNAME}}/fastapi:latest        
